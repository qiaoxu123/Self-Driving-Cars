[MUSIC] In the last lesson, we described how
to divide data sets into training, validation, and testing splits, and interpret the results of evaluating
the loss function on each of these splits. We also emphasize that most of the time
we tend to suffer from overfitting rather than underfitting after
training the network. In this lesson, we'll explore some
ways to reduce overfitting by applying regularization strategies during training. As a result of regularization, our
networks will generalize well to new data, and we'll be able to use them more
effectively outside of the lab. Let's walk through an iteration of neural
network development on a toy example. We want to separate a 2D Cartesian space
into two components, orange and blue. Any point belonging to the blue
space should be labelled class 1, while any point belonging to the orange
space should be labelled class 2. However, we do not have direct access
to these classes or their boundaries. Instead we only have access
to sensor measurements that provide us with examples of
points and their corresponding class. Unfortunately, our sensor is also noisy, that means it sometimes
provides the incorrect label. The label points in the blue space as
class 2, and in orange space as class 1. Our problem amounts to finding the space
classification from the noisy sensor data. We begin by collecting
data from the sensor and splitting them into 60-40
training validation splits. The training splits is shown here
as points with white out lines, and the validation splits is shown here
as points with black out lines. Let's use a simple neuron
network with one layer and two hidden units per layer
to classify measurements. Using this design choice, we get
that following space classification. The training set loss is 0.264 close
to the validation set loss of 0.2268. But it's still much higher than
the minimum achievable loss of 0.1. This is a clear case of underfitting. When we compare the results of our
network classification to the true space classification, we see that
the neural network fail to capture the complexity of
the problem at hand, and did not correctly segment the space
into four compartments as required. To resolve underfitting issues, we
increase the network size by adding five additional layers, and increase the number
of hidden units to six units per layer. Our model is now much more expressive, so it should be able to better
represent the true classification. We go ahead and train our model again,
then test to see how well we have done. We noticed that our
validation set loss result of 0.45 is much higher than our
training set loss result of 0.1. The training set loss, however, is equal to the minimum achievable
loss of 0.1 on this task. We are in a state of overfitting
to the training data. Overfitting is caused by the network
learning the noise in the training data. Because the neural network has so
many parameters, it is able to curve out small regions in
the space that correspond to the noisy training examples as shown
inside the red circles. This usually happens when we increase
the network size too much for the problem at hand. Again, we have learned that one way
to remedy over fitting is through regularization. Let's check out the first regularization
method commonly used for neural networks. The most traditional form of
regularization applicable to neural networks is the concept
of parameter norm penalties. This approach limits the capacity of the
model by adding the penalty omega of theta to the objective function. We add the norm penalty to
our existing loss function using our weighting parameter alpha. Alpha is a new hyperparameter that
weights the relative contribution of the norm penalty to the total
value of loss function. Usually, omega of theta is a measure
of how large the value of theta is. Most commonly this measure is an Lp Norm. When P is 1 we have an absolute sum, and
when P is 2 we get the quadratic sum, etc. Furthermore, we usually only constrain
the weights of the neural network. This is motivated by the fact that
the number of weights is much larger than the number of
biases in the neural network. So weight penalty have a much larger
impact on the final network performance. The most common norm penalty used in
neural networks is the L2-norm penalty. The L2-norm penalty tries
to minimize the L2-norm of all the weights in each
layer of the neural network. Let's take a look at the effect of the
L2-norm penalty applied to our problem. Remember that our latest design resulted
in overfitting on the training data set. Adding the L2-norm penalty
the loss function results in a much better estimate of
the space classification, due to a lower validation set loss
over the unregularized network. However, this lower validation set
loss is coupled with an increase in the training set loss from 0.1 to 0.176. In this case the decrease in
the generalization gap is higher than the increase in training set loss. Do be careful not to regularize too much,
however, to avoid falling into
the underfitting regime once again. Adding a norm penalty is quite easy
in most neural network packages. If you suspect over fitting, L2-norm
penalties might be a very easy remedy that will prevent a lot of waste of
time during the design process. As we mentioned earlier in this video,
researchers have developed regularization mechanisms that are specific
to neural networks. One powerful mechanism used
regularly is called dropout. Lets see how dropout gets
applied during network training. The first step of dropout is to choose
a probability which we'll call P sub keep. At every training iteration,
this probability is used to choose a subset of the network
nodes to keep in the network. These nodes can be either hidden units,
output units, or input units. We then proceed to evaluate the output y
after cutting all the connections coming out of this unit. Since we are removing units proportional
to the keep probably, P sub keep, we multiply the final weights by P
sub keep at the ending of training. This is essential to avoid incorrectly
scaling the outputs when we switch to inference for the full network. Dropout can be intuitively explained as
forcing the model to learn with missing input and hidden units. Or in other words,
with different versions of itself. It provides a computationally inexpensive
but powerful method of regularizing a broad family of neural network
models during the training process, leading to significant reductions
in over feeding and practice. Furthermore, dropout does not
significantly limit the type or model of training
procedure that can be used. It works well with nearly any model that
uses a distributed over parameterized representation, and that can be trained
with stochastic gradient descent. Finally, all neural network libraries
have a dropout layer implemented and ready to be used. We recommend using drop out
whenever you have dense feed forward neural network layers. The final form of regularization you
should know about is early stopping. To explain early stopping visually, we
look at the evolution of the loss function of a neuro network evaluated
on the training set. Given enough capacity, the training loss
should be able to decrease to a value close to zero, as the neuro network
memorizes the training data. However, if we have independent
training and validation sets, the validation loss reaches a point
where it starts to increase. This behaviour is typical during
the overfitting regime, and can be resolved via a method
known as early stopping. We discussed earlier that we
can stop the optimization according to various stopping criteria. Early stopping ends training when
the validation loss keeps increasing for a preset number of iterations or epochs. This is usually interpreted at the point
just before the neural network enters the overfitting regime. After stopping the training algorithm, the set of parameters with the lowest
validation loss is returned. As a final note, early stopping should
not be use as a first choice for regularization. As it also limits the training time, which may interfere with
the overall network performance. Congratulations, you are now ready to
start building your own neural networks. In this lesson,
you learned how to improve the performance of the neural network in the key as
it falls into an overfitting regime. There are many more interesting aspects to
neural network design and training, and I urge you to keep exploring this
fascinating field through the additional resources that we've
included with this module. In the next and final lesson in this
module, we will talk about a neural network architecture of huge practical and
historical importance for vision based perception,
the convolutional neural network. See you then [MUSIC]